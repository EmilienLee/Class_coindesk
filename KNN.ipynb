{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /home/datamining/anaconda3/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to a fixed size, then flatten the image into\n",
    "# a list of raw pixel intensities\n",
    "def image_to_feature_vector(image, size = (100, 50)):\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins = (8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "\n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "\n",
    "    # otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "    # personally hate the way this is done\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cheekForKNN'\n",
    "# initialize the raw pixel intensities matrix, the features matrix,\n",
    "# and labels list\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for dirname, dirnames, filenames in os.walk(dataset):\n",
    "    if dirname != dataset:\n",
    "        path, label = os.path.split(dirname)\n",
    "        # grab the list of images that we'll be describing\n",
    "        imagePaths = list(paths.list_images(dirname))\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "        # load the image and extract the class label (assuming that our\n",
    "        # path as the format: /dataset/{class}/{image_num}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "\n",
    "            # extract raw pixel intensity \"features\", followed by a color\n",
    "            # histogram to characterize the color distribution of the pixels\n",
    "            # in the image\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            hist = extract_color_histogram(image)\n",
    "\n",
    "            # update the raw images, features, and labels matricies,\n",
    "            # respectively\n",
    "            rawImages.append(pixels)\n",
    "            features.append(hist)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # show an update every 1,000 images\n",
    "            if i > 0 and i % 1000 == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb accuracy: 77.00%\n",
      "hist accuracy: 72.00%\n"
     ]
    }
   ],
   "source": [
    "# partition the data into training and testing splits, using 80%\n",
    "# of the data for training and the remaining 20% for testing\n",
    "(train_rX, test_rX, train_rY, test_rY) = train_test_split(rawImages, labels, test_size = 0.2, random_state = 51)\n",
    "(train_fX, test_fX, train_fY, test_fY) = train_test_split(features, labels, test_size = 0.2, random_state = 51)\n",
    "\n",
    "# train and evaluate a k-NN classifer on the raw pixel intensities\n",
    "#for i in range(1,101):\n",
    "model_r = KNeighborsClassifier(n_neighbors = 28, n_jobs = 3)\n",
    "model_r.fit(train_rX, train_rY)\n",
    "acc_r = model_r.score(test_rX, test_rY)\n",
    "print(\"rgb accuracy: {:.2f}%\".format(acc_r * 100))\n",
    "# train and evaluate a k-NN classifer on the histogram\n",
    "# representations\n",
    "#for i in range(1,101):\n",
    "model_f = KNeighborsClassifier(n_neighbors = 53, n_jobs = 3)\n",
    "model_f.fit(train_fX, train_fY)\n",
    "acc_f = model_f.score(test_fX, test_fY)\n",
    "print(\"hist accuracy: {:.2f}%\".format(acc_f * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notgood']\n",
      "[[ 0.25  0.75]]\n",
      "['good']\n",
      "[[ 0.71698113  0.28301887]]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('schannel/S__45334544.jpg')\n",
    "pixels = image_to_feature_vector(image)\n",
    "print(model_r.predict(pixels.reshape(1, -1)))\n",
    "print(model_r.predict_proba(pixels.reshape(1, -1)))\n",
    "\n",
    "hist = extract_color_histogram(image)\n",
    "print(model_f.predict(hist.reshape(1, -1)))\n",
    "print(model_f.predict_proba(hist.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model_f, open(\"20180408_final_knn_hsv_schannel_py2\", \"wb\"), protocol = 2)\n",
    "pickle.dump(model_r, open(\"20180408_final_knn_rgb_cheek_py2\", \"wb\"), protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oil\n",
      "[[ 0.  0.  1.]]\n",
      "\n",
      "notgood\n",
      "[[ 0.25  0.75]]\n"
     ]
    }
   ],
   "source": [
    "model_1 = pickle.load(open(\"20180408_final_knn_hsv_schannel.pkl\", \"rb\"))\n",
    "image_1 = cv2.imread('schannel/S__45334562.jpg')\n",
    "hist = extract_color_histogram(image_1)\n",
    "print(model_1.predict(hist.reshape(1, -1))[0])\n",
    "print(model_1.predict_proba(hist.reshape(1, -1)))\n",
    "model_2 = pickle.load(open(\"20180408_final_knn_rgb_cheek.pkl\", \"rb\"))\n",
    "image_2 = cv2.imread('acne/S__45334562.jpg')\n",
    "pixels = image_to_feature_vector(image_2)\n",
    "print(model_2.predict(pixels.reshape(1, -1))[0])\n",
    "print(model_2.predict_proba(pixels.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
